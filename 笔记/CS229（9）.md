# CS 229(9)

## 课程内容

- Setup / Assumption
- Bias Variance
- Approx Estim
- empirical risk minimize
- uniform convergence
- VC dimension



## Assumptions

- 本课程中的大多数学习算法有两个主要假设
  - 数据遵循某种分布：$(x, y) \sim D$，train和test数据集都来自于同一分布
  - 所有样本都是独立采样的（Independent samples)
    - 如下图所示：s是随机变量，得到的假设也是随机变量
    - 在统计学角度，把Learning alg称为Estimator，$\hat \theta$（模型参数）也遵循某种采样，也是随机变量
    - 还存在$\theta^*$ 作为超参数或者“True" params, 不是随机变量

![image-20230412090621532](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230412090621532.png)



## Bias /Varience

从数据角度：

![image-20230412094125177](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230412094125177.png)

- 欠拟合
- 正确拟合
- 过拟合

从参数角度

![image-20230412094425589](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230412094425589.png)

- 点数是训练集样本数
- 可以看到中间的五角星是目标分布

![image-20230412094551194](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230412094551194.png)

- 从左到右Variance逐渐变大（离散度逐渐变高）
- 从下到上Bias逐渐变大，偏置程度变高



Q:在数据视图中过拟合（高Variance）模型有更多的theta吗？

A:Yes,在示例中只使用两个参数进行演示，在高维空间中它会散布在空间，这里只是为了好演示



- $m->\infin -> var[\hat \theta] -> 0$
- 统计效率：用于权衡模型的拟合速率
  - 公式：$\frac {\part \{var[\hat \theta\}}{\part m}$ 当$m->0$
- $\hat \theta=>\theta^* 当m->\infin$，则称之为一致算法



Q:统计效率数学表达是什么

A:进行一定的补充如上



Q:怎么理解一致算法

A:当数量级越大时，你的$\hat \theta$也就是你的参数分布，会逐渐的趋向于某一个常数$\theta^*$

Q：听不清

A:在给定m大小的情况下，bias和Variance都是算法的属性

Q:听不清

A:你不知道在高偏差/方差的情况下会发生什么，可以通过test和train中的差距去解决，我们在这里只讨论概念，之后会介绍解决方案

## Fighting Variance

1. M->足够的数据量
2. Regularization
   - 在使用正则时需要权衡Bias 和Variance，因为使用正则化也意味着一定程度上会导致Bias下降



#### notation

- $\mathcal{H}-$space of Hypothesis

- $g$-最佳的模型, (g可能不在$\mathcal{H}$中)
- $h^*$-学习到的最佳算法
- $\epsilon(h)$- Risk/Generalization error = $E_{(x,y)\sim D} [I\{h(x)\ne y\}]$

- $\hat \epsilon_s(h)$:经验风险=$\frac 1 m\sum\limits_{i=1}^m I\{h(x^i)\ne y^i\}$
  - 两者的区别在于一个是无限的（真实分布），一个是基于数据集s的（采样/观察数据）

下图讲述了$\mathcal{H}, g, \hat h,h^*$的关系

![image-20230412101909903](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230412101909903.png)



- $\epsilon(g) $-Bayes Error/ irreducible error，即使采用真实的最佳函数，也会产生一些误差
- $\epsilon (h^*) - \epsilon(g)$- Approximation error
- $\epsilon(\hat h) - \epsilon(h^*) $- Estimation error

- $\epsilon(\hat h) = esimation\ error+\\ Approx\ error+\\ Irriducable\ error$
  - 无论如何采样采取何种算法，都无法减少$\epsilon (g)$
  - 你选择的模型本身就有限制，则可能会增大近似误差Approx error
  - 当你选择的数据过少，拟合数据不足，则会增大估算误差
  - Estimation error分为Estimation var + Estimation Bias
  - Approx error + Estimation Bias构成整体的Bias 

- High Variance:基本上就是数据集太小，导致偏差太大



## Fight High Bias

- make $\mathcal{H}$更大
  - 这是一种权衡，当你的$\mathcal{H}$变大时，你的variance也会因为无法寻找精确地$h^*$变大
- 添加正则化会缩小假设空间，所以这会引入偏差



## 经验风险最小化（ERM）

- 经验风险最小化是一种机器学习算法

  ![image-20230412105146737](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230412105146737.png)

- $\hat h_{ERM} = argmin_{h\in \mathcal{H}} \frac 1m \sum\limits_{i=1}^m I\{h(x^i) \ne y\}$



## uniform convergence(一致收敛)

1. 如果我们进行ERM，那么我们只是最小化损失函数 $\hat \epsilon(h)$ vs $\epsilon (h)$
2. 我们所学假设的泛化错误和该类最好的泛化错误的比较$\epsilon (\hat h) $vs $\epsilon(h^*)$

### Tools

1. Union Bound
   - $A_1, A_2, ...A_K$ 是k个不同的随机事件（可能不是独立的）->$P(A_1\cup A_2...\cup A_k) \le P(A_1) + ...+P(A_K)$
2. Hoeffding inequality(霍夫丁不等式)
   - $z_1,z_2,....z_m \sim Bernouli(\phi)$
   - $\hat \phi = \frac 1 m \sum\limits_{i= 1}^m z_i$
   - 令$\gamma>0$[margin]
   - $Pr[|\hat \phi - \phi|>\gamma] \le \alpha e^{-\alpha \gamma^2m}$
   - $|\hat \phi - \phi| $误差
   - $\gamma$:margin
   - 随着m增大，估计偏差就会减少



Q:$h^*$是$m->\infin$时$\hat h$的极限吗？

A:不一定，必须你的学习算法是一致的，才有这个性质，我们在之前已经讨论过一致算法的问题,不一致算法，就不会出现这样的性质



Q:上述不等式是hoeffding‘s不等式的特殊有限形式吗？

A:是的，我们限制了分布为伯努利分布



Q:听不清 

A:最大似然估计通常是一致的，虽然一致，但是……，我不太确定



Q:若果有一个类似神经网络的算法 非凸算法，可能会得到不一致的结果

A:非凸性是估计偏差的一部分，理论上你总是可以通过梯度下降法找到神经网络的最小值，但是无法完全解决（有点结巴不太懂）





![image-20230412111928451](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230412111928451.png)

![image-20230412112144108](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230412112144108.png)

- 将训练样本的所有值相加取平均值，得到的高度与实现一致，也就是虚线的期望值就是实线高度
- 运用Hoeffding’s inequality，如果我们提升m（上述曲线对应于特定的m大小），虚线会更加贴近实线
- 实际上我们预先使用ERM会选择一个最佳的h，这样的话统计全部假设h的信息就没有那么大的用处了
- 我们使用一致收敛（跳过数学）



#### 有限假设类

第一个问题：经验误差和泛化误差

- $|\mathcal{H}|=R$是有限的

- $P(\exist h \in \mathcal{H} \ |\hat\epsilon _s(h) - \epsilon(h)| >\gamma) \gt K\alpha exp(-\alpha\gamma^2m)$
- $P(\exist h \in \mathcal{H} \ |\hat\epsilon _s(h) - \epsilon(h)| \le \gamma) \ge 1 - K\alpha exp(-\alpha\gamma^2m)$



![image-20230412113241887](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230412113241887.png)



- Fix $\gamma, r \gt 0$

- $m \ge \frac 1 {\alpha\gamma^2} log \frac {\alpha K}{\delta}$



第二个问题：泛化误差和最优泛化误差

![image-20230412113643134](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230412113643134.png)

- $\epsilon (\hat h) \le \hat\epsilon (\hat h) + \gamma\\ \le \hat \epsilon(h^*) + \delta\\\le\epsilon(h^*) + 2\gamma$

=>$$





## VC dimension

$VC(\mathcal{H})$