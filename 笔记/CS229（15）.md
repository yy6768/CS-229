# CS229 （15）

## 课程内容

- EM收敛性
- 高斯分布的特性
- factor analysis
- 高斯分布
- EM的推导



## 高斯混合模型复习

- E-step ：$w^{(i)} = Q(z^{(i)} = j)= p(z^{(i)} = j |x^{(i)};\phi,\mu,\Sigma)$

- M-step:$max_{\phi,\mu,\Sigma} \sum_i\sum_{z^{(i)}}Q(z^{(i)}) \log \frac {p(x^{(i)},z^{(i)};\phi,\mu\Sigma)}{Q(z^{(i)})}$

![image-20230428093901256](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230428093901256.png)

![image-20230428094011557](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230428094011557.png)

- 为了最大似然，我们需要求出各个参数的导数

![image-20230428094125637](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230428094125637.png)	导数为0，求出$\mu_l = \frac{\sum_{i=1}^m w_l^{(i)}x^{(i)}}{\sum\limits_{i =1}^m w_l^{(i)}}$



$J(\theta, Q) = \sum_i\sum_jQ(z^{(i)})\log \frac {p(x^{(i)},z^{(i)};\phi,\mu\Sigma)}{Q(z^{(i)})}$

使用Jessen不等式可以证明$l(\theta) \ge J(\theta,Q)$

- E-step做的是最大化J with Q
- M-step做的是最大化J with $\theta$



## Factor analysis 

- 当数据量远大于特征维度时，EM算法可以起到很好的效果
- 但是当$m\approx n \or m << n$时，我们需要某种算法处理小数据

- 当时使用高斯模型的时候，会发现在最大似然时，协方差矩阵是奇异的（不可逆的），几何上，高斯模型被无限拉长

  ![image-20230428100134710](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230428100134710.png)

- ![image-20230428101032740](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230428101032740.png)

- 我们使用高斯分布，假设所有随机变量不相关，但是对于同一个房间的温度传感器，多问题心理测试很难满足这个要求



### 定义

- $\mu \in R^N, \Lambda \in R^{n \times k},\Phi\in\mathbb{R}^{n\times n}$

- $z \sim \mathcal{N}(0,I) \\ x|z \sim \mathcal{N} (\mu + \Lambda z, \phi)$

把数据点映射到k维的高斯分布





## 多元高斯分布性质

一些关于多元高斯分布的复习

x = $\begin{bmatrix}x_1 \\ x_2\end{bmatrix}$

![image-20230428110951519](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230428110951519.png)

- 边缘概率分布

  ![image-20230428111037871](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230428111037871.png)

  积分得到发现边缘概率分布就是单个高斯分布$x_1 \sim N(\mu_1,\Sigma_1)$

- 条件概率分布

![image-20230428111326959](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230428111326959.png)



## Factor analysis推导

1. 推导$p(x,z)$

2. 计算联合分布的E和$\Sigma$

   ![image-20230428111627570](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230428111627570.png)

3. ![image-20230428112331534](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230428112331534.png)

- 有一个很大的问题是最后的极大似然估计问题是 **hard（难问题）**，所以选择使用EM算法来进行优化

## EM for Factor Analysis

- E-step:

  - 计算

    ![image-20230428112729857](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230428112729857.png)

  - 通过gaussian condition distribution计算可以得到，相对简单

- M-step:

  - 需要求出：

    ![image-20230428113042495](http://typora-yy.oss-cn-hangzhou.aliyuncs.com/img/image-20230428113042495.png)

  - 通过期望来计算上述的积分